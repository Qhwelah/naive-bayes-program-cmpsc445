{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228a8451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#A skeleton for implementing Naive Bayes Classifier in Python.\n",
    "## Author: Md Faisal Kabir\n",
    "## Spring 2025\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "\n",
    "# Change these file names to swap programs\n",
    "trainingFile = \"irisTraining.txt\"\n",
    "testingFile = \"irisTesting.txt\"\n",
    "\n",
    "# Specify if the attributes are continuous (cont) or categorical (cat)\n",
    "attributeType = \"cont\" \n",
    "\n",
    "# Xtrain = numpy.loadtxt(trainingFile)\n",
    "XtrainPandas = pandas.read_csv(trainingFile, sep=' ')\n",
    "\n",
    "n = XtrainPandas.shape[0]\n",
    "d = XtrainPandas.shape[1]-1\n",
    "print(n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fafbd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal_Length for classification -1: mean 5.771212121212121, stddev 0.9419725868157492\n",
      "\n",
      "Sepal_Width for classification -1: mean -1.3181818181818181, stddev 0.7743799685324617\n",
      "\n",
      "Petal_Length for classification -1: mean 3.548484848484849, stddev 2.0803285557254894\n",
      "\n",
      "Petal_Width for classification -1: mean 0.22272727272727275, stddev 1.0916177768016468\n",
      "\n",
      "skipping Classification\n",
      "-----------------------------\n",
      "Sepal_Length for classification 1: mean 5.847058823529412, stddev 0.5124127681076909\n",
      "\n",
      "Sepal_Width for classification 1: mean -1.388235294117647, stddev 0.31981500891718434\n",
      "\n",
      "Petal_Length for classification 1: mean 3.005882352941176, stddev 2.5404534523024638\n",
      "\n",
      "Petal_Width for classification 1: mean 1.3, stddev 0.21602468994692872\n",
      "\n",
      "skipping Classification\n"
     ]
    }
   ],
   "source": [
    "#Training... Collect mean and standard deviation for each dimension for each class..\n",
    "#Also, calculate P(C+) and P(C-)\n",
    "\n",
    "# value trackers for classification -1\n",
    "col_mean_vals_cn1 = []  \n",
    "col_stddev_vals_cn1 = []\n",
    "\n",
    "# value trackers for classification +1\n",
    "col_mean_vals_cp1 = []  \n",
    "col_stddev_vals_cp1 = []\n",
    "\n",
    "if(attributeType == \"cont\"):\n",
    "    #print(XtrainPandas)\n",
    "    SplitXtrain = dict(tuple(XtrainPandas.groupby('Classification')))\n",
    "    # print(SplitXtrain[-1])\n",
    "    # print(SplitXtrain[1])\n",
    "\n",
    "    for col in SplitXtrain[-1]:\n",
    "        if(col == 'Classification'):\n",
    "            print(f\"skipping {col}\")\n",
    "            break\n",
    "        col_mean_vals_cn1.append(SplitXtrain[-1][col].mean())\n",
    "        col_stddev_vals_cn1.append(SplitXtrain[-1][col].std())\n",
    "        print(f\"{col} for classification -1: mean {col_mean_vals_cn1[len(col_mean_vals_cn1)-1]}\" \\\n",
    "            + f\", stddev {col_stddev_vals_cn1[len(col_stddev_vals_cn1)-1]}\\n\")\n",
    "    \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for col in SplitXtrain[1]:\n",
    "        if(col == 'Classification'):\n",
    "            print(f\"skipping {col}\")\n",
    "            break\n",
    "        col_mean_vals_cp1.append(SplitXtrain[1][col].mean())\n",
    "        col_stddev_vals_cp1.append(SplitXtrain[1][col].std())\n",
    "        print(f\"{col} for classification 1: mean {col_mean_vals_cp1[len(col_mean_vals_cp1)-1]}\" \\\n",
    "            + f\", stddev {col_stddev_vals_cp1[len(col_stddev_vals_cp1)-1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing .....\n",
    "Xtest = numpy.loadtxt(testingFile)\n",
    "nn = Xtest.shape[0] # Number of points in the testing data.\n",
    "\n",
    "tp = 0 #True Positive\n",
    "fp = 0 #False Positive\n",
    "tn = 0 #True Negative\n",
    "fn = 0 #False Negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c54305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over all points in testing data\n",
    "  #For each point find the P(C+|Xi) and P(C-|Xi) and decide if the point belongs to C+ or C-..\n",
    "  #Recall we need to calculate P(Xi|C+)*P(C+) ..\n",
    "  #P(Xi|C+) = P(Xi1|C+) * P(Xi2|C+)....P(Xid|C+)....Do the same for P(Xi|C-)\n",
    "  #Now that you've calculate P(Xi|C+) and P(Xi|C-), we can decide which is higher \n",
    "  #P(Xi|C-)*P(C-) or P(Xi|C-)*P(C-) ..\n",
    "  #increment TP,FP,FN,TN accordingly, remember the true lable for the ith point is in Xtest[i,d]\n",
    "\n",
    "#}\n",
    "\n",
    "#Calculate all the measures required.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
